import numpy as np
import matplotlib
import matplotlib.pyplot as plt

def plotter(iterations, data1, data2, data3, labelY, title):

    plt.plot(iterations, data1, 'b-', label='Value Iteration')
    plt.plot(iterations, data2, 'r-', label='Policy Iteration')
    plt.plot(iterations, data3, 'g-', label='Q Learning')
    # plt.scatter(sorted_data, yvals, linestyle='--', marker="o", color='black')

    # Plot the cdf
    # plt.yscale('log')
    # plt.xscale('log')
    
    # plt.ylim((0, 1.1))
    plt.ylabel(labelY)
    plt.xlabel("Iterations")
    plt.margins(0.02)
    plt.legend(loc='upper right')
    plt.grid(True)
    # plt.yscale('log')
    plt.title(title)
    plt.show()


def main():
    """
    # This is for easy graph
    Iterations = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100]
    VI_steps = [157,1056,62,34,13,14,14,11,13,12,9,11,17,13,13,12,11,16,11,9,10,10,11,11,11,12,11,14,11,13,19,22,9,9,12,17,13,13,10,9,11,10,10,10,13,9,12,12,10,12,13,12,9,10,9,15,18,12,10,10,9,10,17,11,11,11,14,9,11,11,10,15,10,9,10,10,20,12,9,10,9,10,10,11,13,13,15,10,14,9,13,12,10,18,9,12,11,19,9,15]
    PI_steps = [111,53,269,26,11,14,12,11,10,11,12,9,10,12,9,14,10,10,14,10,15,11,11,10,10,10,13,13,10,10,12,12,21,11,9,12,11,10,14,11,11,12,10,10,13,12,14,13,9,9,12,9,11,9,13,9,14,10,12,9,10,10,11,10,10,11,9,22,16,12,16,11,10,10,14,13,9,10,14,11,15,10,10,11,13,9,10,11,13,12,12,10,9,15,9,13,11,10,10,10]
    QL_steps = [71,17,17,28,21,10,14,16,16,14,25,14,29,28,15,13,20,22,13,16,17,46,15,180,20,18,11,10,85,9,11,25,15,27,11,12,13,19,12,19,17,11,11,24,19,10,11,11,13,15,22,15,14,15,11,15,10,9,10,13,13,9,13,14,15,17,9,18,38,22,9,34,13,14,12,9,10,16,13,10,10,19,9,10,14,20,12,16,16,10,22,16,17,13,19,80,10,38,12,16]


    VI_time = [27,3,2,2,2,2,3,3,3,3,3,4,10,4,2,3,2,3,3,3,3,3,3,3,3,4,9,2,2,3,3,3,3,3,3,3,4,7,4,3,4,4,4,6,5,4,8,4,4,5,4,5,5,5,6,12,12,12,13,16,7,7,7,7,7,7,7,8,8,8,13,7,8,9,9,10,8,7,7,7,7,14,16,17,18,17,16,17,17,19,9,8,8,8,8,8,8,9,9,9]
    PI_time = [2,1,0,1,1,1,1,2,2,2,2,2,2,2,3,3,4,4,4,4,4,4,11,3,3,3,5,4,5,5,5,5,5,5,5,5,6,5,5,6,6,6,6,7,7,6,7,8,14,19,19,19,19,20,20,21,21,21,21,21,22,23,22,23,28,14,13,10,11,10,13,17,14,14,11,11,13,13,14,16,14,17,12,13,11,11,14,15,15,16,10,10,12,11,12,11,14,12,11,12]
    QL_time = [7,2,2,4,2,1,1,1,1,1,1,1,2,2,1,1,1,1,1,1,3,3,2,2,2,1,2,2,2,3,7,4,3,2,2,2,2,2,2,2,2,2,2,2,2,2,3,2,4,4,2,3,4,3,7,9,7,7,6,8,7,10,8,9,8,8,9,10,11,9,12,10,10,8,10,11,8,9,12,9,8,11,12,9,11,9,9,13,4,4,4,3,4,3,3,4,3,4,3,5]


    VI_rewards = [-55.0,-954.0,40.0,68.0,89.0,88.0,88.0,91.0,89.0,90.0,93.0,91.0,85.0,89.0,89.0,90.0,91.0,86.0,91.0,93.0,92.0,92.0,91.0,91.0,91.0,90.0,91.0,88.0,91.0,89.0,83.0,80.0,93.0,93.0,90.0,85.0,89.0,89.0,92.0,93.0,91.0,92.0,92.0,92.0,89.0,93.0,90.0,90.0,92.0,90.0,89.0,90.0,93.0,92.0,93.0,87.0,84.0,90.0,92.0,92.0,93.0,92.0,85.0,91.0,91.0,91.0,88.0,93.0,91.0,91.0,92.0,87.0,92.0,93.0,92.0,92.0,82.0,90.0,93.0,92.0,93.0,92.0,92.0,91.0,89.0,89.0,87.0,92.0,88.0,93.0,89.0,90.0,92.0,84.0,93.0,90.0,91.0,83.0,93.0,87.0]
    PI_rewards = [-9.0,49.0,-167.0,76.0,91.0,88.0,90.0,91.0,92.0,91.0,90.0,93.0,92.0,90.0,93.0,88.0,92.0,92.0,88.0,92.0,87.0,91.0,91.0,92.0,92.0,92.0,89.0,89.0,92.0,92.0,90.0,90.0,81.0,91.0,93.0,90.0,91.0,92.0,88.0,91.0,91.0,90.0,92.0,92.0,89.0,90.0,88.0,89.0,93.0,93.0,90.0,93.0,91.0,93.0,89.0,93.0,88.0,92.0,90.0,93.0,92.0,92.0,91.0,92.0,92.0,91.0,93.0,80.0,86.0,90.0,86.0,91.0,92.0,92.0,88.0,89.0,93.0,92.0,88.0,91.0,87.0,92.0,92.0,91.0,89.0,93.0,92.0,91.0,89.0,90.0,90.0,92.0,93.0,87.0,93.0,89.0,91.0,92.0,92.0,92.0]
    QL_rewards = [31.0,85.0,85.0,74.0,81.0,92.0,88.0,86.0,86.0,88.0,77.0,88.0,73.0,74.0,87.0,89.0,82.0,80.0,89.0,86.0,85.0,56.0,87.0,-78.0,82.0,84.0,91.0,92.0,17.0,93.0,91.0,77.0,87.0,75.0,91.0,90.0,89.0,83.0,90.0,83.0,85.0,91.0,91.0,78.0,83.0,92.0,91.0,91.0,89.0,87.0,80.0,87.0,88.0,87.0,91.0,87.0,92.0,93.0,92.0,89.0,89.0,93.0,89.0,88.0,87.0,85.0,93.0,84.0,64.0,80.0,93.0,68.0,89.0,88.0,90.0,93.0,92.0,86.0,89.0,92.0,92.0,83.0,93.0,92.0,88.0,82.0,90.0,86.0,86.0,92.0,80.0,86.0,85.0,89.0,83.0,22.0,92.0,64.0,90.0,86.0]

    plotter (Iterations, VI_steps, PI_steps, QL_steps, "No. of steps/actions", "Steps/actions to goal vs. Iterations")
    plotter (Iterations, VI_time, PI_time, QL_time, "Time in ms", "Time (ms) to optimal policy vs. Iterations")
    plotter (Iterations, VI_rewards, PI_rewards, QL_rewards, "Reward", "Rewards at optimal policy vs. Iterations")
    

    # This is for hardWorld
    Iterations = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100]
    VI_steps = [4640,2517,6680,74,30,23,39,29,30,22,24,28,24,37,26,27,28,25,23,31,33,27,32,32,23,25,26,30,28,31,28,29,26,21,21,24,36,28,23,25,24,26,23,29,24,25,25,25,22,22,26,28,27,22,24,29,31,25,26,23,26,22,28,23,30,25,30,26,21,22,31,27,24,26,27,25,21,27,32,28,30,29,24,30,28,30,25,23,27,24,21,27,29,24,25,29,26,22,27,24]
    PI_steps = [5544,3139,935,1021,190,39,182,50,28,33,35,26,29,31,24,29,24,22,26,22,22,23,21,29,30,30,22,21,33,26,21,29,28,33,27,35,23,29,28,24,31,29,33,26,27,25,29,23,26,21,28,25,28,25,32,30,25,25,23,25,25,24,35,27,48,25,26,26,33,33,21,28,29,24,29,35,29,24,25,31,27,23,22,28,27,24,25,31,26,25,29,32,32,21,24,28,32,25,28,24]
    QL_steps = [492,422,334,545,164,136,297,275,250,243,77,62,72,87,113,111,139,107,67,62,61,68,197,111,46,76,62,59,47,243,49,65,485,35,48,101,53,64,66,60,26,72,38,81,63,85,53,34,51,74,41,51,40,82,51,83,25,57,27,85,53,91,228,82,87,72,32,67,94,109,52,55,69,45,77,78,61,69,71,29,40,119,30,56,141,48,61,78,71,54,60,64,59,45,38,37,51,38,85,49]

    VI_time = [50,4,4,11,13,23,10,9,9,11,12,12,20,14,15,15,16,18,36,43,47,35,21,22,21,24,24,28,25,26,26,27,38,61,68,69,72,36,32,35,35,35,37,38,40,38,38,39,40,40,41,76,101,103,105,45,47,46,47,49,50,52,52,55,51,53,53,54,55,55,56,112,137,137,141,103,61,61,62,63,63,63,66,69,72,80,66,70,72,71,69,73,75,74,74,91,76,78,77,75]
    PI_time = [8,7,8,9,11,12,12,15,15,17,20,32,23,26,28,28,27,28,32,36,38,40,38,37,40,40,42,43,49,46,48,50,52,52,55,57,56,60,60,65,80,68,66,73,72,79,74,74,75,77,82,85,87,86,90,88,91,91,92,93,99,99,100,109,101,103,101,108,106,108,115,113,119,115,117,115,125,121,125,132,132,133,137,130,133,136,139,147,160,147,160,165,146,152,149,150,153,156,158,155]
    QL_time = [13,5,6,10,6,8,6,5,8,12,8,13,7,8,8,7,7,8,7,8,8,9,9,8,10,10,9,10,10,12,11,10,24,10,10,10,10,12,11,12,13,11,10,13,11,11,15,11,15,13,11,14,14,19,15,14,14,13,15,18,17,16,16,14,14,17,14,19,17,18,16,16,17,20,17,16,17,17,21,18,23,21,18,21,21,17,19,21,23,21,21,21,25,19,21,29,22,19,18,18]

    VI_rewards = [-4538.0,-2415.0,-6578.0,28.0,72.0,79.0,63.0,73.0,72.0,80.0,78.0,74.0,78.0,65.0,76.0,75.0,74.0,77.0,79.0,71.0,69.0,75.0,70.0,70.0,79.0,77.0,76.0,72.0,74.0,71.0,74.0,73.0,76.0,81.0,81.0,78.0,66.0,74.0,79.0,77.0,78.0,76.0,79.0,73.0,78.0,77.0,77.0,77.0,80.0,80.0,76.0,74.0,75.0,80.0,78.0,73.0,71.0,77.0,76.0,79.0,76.0,80.0,74.0,79.0,72.0,77.0,72.0,76.0,81.0,80.0,71.0,75.0,78.0,76.0,75.0,77.0,81.0,75.0,70.0,74.0,72.0,73.0,78.0,72.0,74.0,72.0,77.0,79.0,75.0,78.0,81.0,75.0,73.0,78.0,77.0,73.0,76.0,80.0,75.0,78.0]
    PI_rewards = [-5442.0,-3037.0,-833.0,-919.0,-88.0,63.0,-80.0,52.0,74.0,69.0,67.0,76.0,73.0,71.0,78.0,73.0,78.0,80.0,76.0,80.0,80.0,79.0,81.0,73.0,72.0,72.0,80.0,81.0,69.0,76.0,81.0,73.0,74.0,69.0,75.0,67.0,79.0,73.0,74.0,78.0,71.0,73.0,69.0,76.0,75.0,77.0,73.0,79.0,76.0,81.0,74.0,77.0,74.0,77.0,70.0,72.0,77.0,77.0,79.0,77.0,77.0,78.0,67.0,75.0,54.0,77.0,76.0,76.0,69.0,69.0,81.0,74.0,73.0,78.0,73.0,67.0,73.0,78.0,77.0,71.0,75.0,79.0,80.0,74.0,75.0,78.0,77.0,71.0,76.0,77.0,73.0,70.0,70.0,81.0,78.0,74.0,70.0,77.0,74.0,78.0]
    QL_rewards = [-390.0,-320.0,-232.0,-443.0,-62.0,-34.0,-195.0,-173.0,-148.0,-141.0,25.0,40.0,30.0,15.0,-11.0,-9.0,-37.0,-5.0,35.0,40.0,41.0,34.0,-95.0,-9.0,56.0,26.0,40.0,43.0,55.0,-141.0,53.0,37.0,-383.0,67.0,54.0,1.0,49.0,38.0,36.0,42.0,76.0,30.0,64.0,21.0,39.0,17.0,49.0,68.0,51.0,28.0,61.0,51.0,62.0,20.0,51.0,19.0,77.0,45.0,75.0,17.0,49.0,11.0,-126.0,20.0,15.0,30.0,70.0,35.0,8.0,-7.0,50.0,47.0,33.0,57.0,25.0,24.0,41.0,33.0,31.0,73.0,62.0,-17.0,72.0,46.0,-39.0,54.0,41.0,24.0,31.0,48.0,42.0,38.0,43.0,57.0,64.0,65.0,51.0,64.0,17.0,53.0]

    plotter (Iterations, VI_steps, PI_steps, QL_steps, "No. of steps/actions", "Steps/actions to goal vs. Iterations")
    plotter (Iterations, VI_time, PI_time, QL_time, "Time in ms", "Time (ms) to optimal policy vs. Iterations")
    plotter (Iterations, VI_rewards, PI_rewards, QL_rewards, "Reward", "Rewards at optimal policy vs. Iterations")
    """
    
    # This is for hardWorld2
    Iterations = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100]
    VI_steps = [1159,3761,11342,604,1033,224,41,48,34,33,26,35,29,42,30,28,25,30,24,36,28,33,25,32,26,32,29,25,29,30,27,21,31,28,34,29,29,31,28,27,28,28,23,38,31,28,24,33,35,32,37,27,33,22,31,31,31,27,23,22,32,33,30,31,27,35,29,26,26,27,32,26,22,28,27,31,30,34,31,29,28,31,35,35,31,39,26,28,31,31,25,29,28,36,31,31,36,26,37,37]
    PI_steps = [4740,2658,29271,110696,20934,1052,19315,969,231,41,48,30,28,32,37,32,29,30,34,37,23,32,25,42,27,25,28,35,32,34,30,30,39,32,27,31,25,28,29,25,25,28,24,36,33,31,25,28,33,39,31,26,27,35,28,25,30,30,35,26,33,26,25,28,30,28,28,26,27,34,25,28,28,25,25,32,22,26,24,29,26,35,23,32,27,32,29,32,23,28,26,26,31,24,36,28,32,40,30,25]
    QL_steps = [1133,550,236,651,554,464,175,103,511,84,151,53,267,158,491,98,95,69,194,82,77,89,180,44,53,464,60,53,243,50,50,62,161,99,141,165,73,68,38,50,50,40,36,58,107,84,41,73,82,75,92,48,187,45,45,92,109,107,84,151,72,147,91,37,154,108,44,97,87,34,44,59,77,92,204,155,54,56,56,111,61,84,71,68,60,109,77,91,81,58,58,61,111,134,56,170,46,35,49,82]

    VI_time = [48,13,7,12,14,7,8,9,11,12,12,20,14,14,14,15,18,39,44,45,28,20,21,22,23,24,27,25,27,27,27,44,70,70,74,66,33,33,33,34,37,37,42,42,41,43,41,41,43,59,107,106,106,62,50,52,48,50,51,53,54,57,53,55,56,57,58,59,61,131,148,143,146,85,62,63,64,65,66,67,68,68,70,72,72,73,76,74,77,76,77,78,91,82,82,82,83,82,83,85]
    PI_time = [8,8,7,9,13,13,15,17,19,21,22,24,25,27,29,68,33,35,35,39,41,42,44,46,48,47,49,51,54,59,55,55,59,59,60,61,63,67,66,69,76,72,76,76,79,80,88,97,84,88,87,93,94,92,94,95,98,99,101,101,103,104,112,116,117,112,117,115,117,123,125,127,125,124,138,125,133,143,145,138,139,139,147,144,147,145,148,150,161,154,157,156,159,164,172,165,163,164,171,179]
    QL_time = [16,7,23,19,18,12,15,10,14,11,11,13,14,13,14,12,14,14,14,12,19,14,16,12,16,15,12,16,19,19,21,21,20,18,20,25,18,22,16,24,19,23,17,26,28,21,20,24,23,23,20,22,24,23,21,21,24,22,20,33,26,27,27,24,32,22,24,23,29,22,21,26,32,23,24,28,24,23,27,32,30,29,24,23,24,32,28,28,27,26,31,32,32,25,44,32,28,36,28,30]

    VI_rewards = [-1057.0,-3659.0,-11240.0,-502.0,-931.0,-122.0,61.0,54.0,68.0,69.0,76.0,67.0,73.0,60.0,72.0,74.0,77.0,72.0,78.0,66.0,74.0,69.0,77.0,70.0,76.0,70.0,73.0,77.0,73.0,72.0,75.0,81.0,71.0,74.0,68.0,73.0,73.0,71.0,74.0,75.0,74.0,74.0,79.0,64.0,71.0,74.0,78.0,69.0,67.0,70.0,65.0,75.0,69.0,80.0,71.0,71.0,71.0,75.0,79.0,80.0,70.0,69.0,72.0,71.0,75.0,67.0,73.0,76.0,76.0,75.0,70.0,76.0,80.0,74.0,75.0,71.0,72.0,68.0,71.0,73.0,74.0,71.0,67.0,67.0,71.0,63.0,76.0,74.0,71.0,71.0,77.0,73.0,74.0,66.0,71.0,71.0,66.0,76.0,65.0,65.0]
    PI_rewards = [-4638.0,-2556.0,-29169.0,-110594.0,-20832.0,-950.0,-19213.0,-867.0,-129.0,61.0,54.0,72.0,74.0,70.0,65.0,70.0,73.0,72.0,68.0,65.0,79.0,70.0,77.0,60.0,75.0,77.0,74.0,67.0,70.0,68.0,72.0,72.0,63.0,70.0,75.0,71.0,77.0,74.0,73.0,77.0,77.0,74.0,78.0,66.0,69.0,71.0,77.0,74.0,69.0,63.0,71.0,76.0,75.0,67.0,74.0,77.0,72.0,72.0,67.0,76.0,69.0,76.0,77.0,74.0,72.0,74.0,74.0,76.0,75.0,68.0,77.0,74.0,74.0,77.0,77.0,70.0,80.0,76.0,78.0,73.0,76.0,67.0,79.0,70.0,75.0,70.0,73.0,70.0,79.0,74.0,76.0,76.0,71.0,78.0,66.0,74.0,70.0,62.0,72.0,77.0]
    QL_rewards = [-1031.0,-448.0,-134.0,-549.0,-452.0,-362.0,-73.0,-1.0,-409.0,18.0,-49.0,49.0,-165.0,-56.0,-389.0,4.0,7.0,33.0,-92.0,20.0,25.0,13.0,-78.0,58.0,49.0,-362.0,42.0,49.0,-141.0,52.0,52.0,40.0,-59.0,3.0,-39.0,-63.0,29.0,34.0,64.0,52.0,52.0,62.0,66.0,44.0,-5.0,18.0,61.0,29.0,20.0,27.0,10.0,54.0,-85.0,57.0,57.0,10.0,-7.0,-5.0,18.0,-49.0,30.0,-45.0,11.0,65.0,-52.0,-6.0,58.0,5.0,15.0,68.0,58.0,43.0,25.0,10.0,-102.0,-53.0,48.0,46.0,46.0,-9.0,41.0,18.0,31.0,34.0,42.0,-7.0,25.0,11.0,21.0,44.0,44.0,41.0,-9.0,-32.0,46.0,-68.0,56.0,67.0,53.0,20.0]


    plotter (Iterations, VI_steps, PI_steps, QL_steps, "No. of steps/actions", "Steps/actions to goal vs. Iterations")
    plotter (Iterations, VI_time, PI_time, QL_time, "Time in ms", "Time (ms) to optimal policy vs. Iterations")
    plotter (Iterations, VI_rewards, PI_rewards, QL_rewards, "Reward", "Rewards at optimal policy vs. Iterations")
if __name__ == "__main__":
    main()